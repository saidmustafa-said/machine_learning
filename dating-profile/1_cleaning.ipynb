{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Report for the okcupid_profile dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# -----------------------------\n",
    "# 1. Load the Dataset\n",
    "# -----------------------------\n",
    "file_path = '../data/okcupid_profiles.csv'  # Updated file path\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import html\n",
    "\n",
    "# # -------------------------------------------------------\n",
    "# # Assume your DataFrame is already loaded (for example):\n",
    "# # df = pd.read_csv(\"your_data.csv\")\n",
    "# # -------------------------------------------------------\n",
    "\n",
    "# # ---------------------------\n",
    "# # Helper Cleaning Functions\n",
    "# # ---------------------------\n",
    "\n",
    "# def clean_speaks(entry):\n",
    "#     \"\"\"\n",
    "#     Cleans the 'speaks' column.\n",
    "#     Splits on commas, removes any parenthetical notes,\n",
    "#     strips whitespace and lowercases the language names.\n",
    "#     Returns a list of cleaned language tokens.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(entry):\n",
    "#         return []\n",
    "#     languages = entry.split(',')\n",
    "#     cleaned = []\n",
    "#     for lang in languages:\n",
    "#         lang_clean = re.sub(r'\\s*\\(.*\\)', '', lang).strip().lower()\n",
    "#         if lang_clean:\n",
    "#             cleaned.append(lang_clean)\n",
    "#     return cleaned\n",
    "\n",
    "# def clean_ethnicity(entry):\n",
    "#     \"\"\"\n",
    "#     Cleans the 'ethnicity' column.\n",
    "#     Splits on commas and forward-slashes, strips extra spaces,\n",
    "#     lowercases tokens.\n",
    "#     Returns a list of cleaned ethnicity tokens.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(entry):\n",
    "#         return []\n",
    "#     tokens = []\n",
    "#     for part in entry.split(','):\n",
    "#         for token in part.split('/'):\n",
    "#             token_clean = token.strip().lower()\n",
    "#             if token_clean:\n",
    "#                 tokens.append(token_clean)\n",
    "#     return tokens\n",
    "\n",
    "# def clean_job(entry):\n",
    "#     \"\"\"\n",
    "#     Cleans the 'job' column.\n",
    "#     Splits on commas and forward-slashes to extract individual tokens,\n",
    "#     strips spaces and lowercases them.\n",
    "#     Returns a list of cleaned job tokens.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(entry):\n",
    "#         return []\n",
    "#     tokens = []\n",
    "#     for part in entry.split(','):\n",
    "#         for token in part.split('/'):\n",
    "#             token_clean = token.strip().lower()\n",
    "#             if token_clean:\n",
    "#                 tokens.append(token_clean)\n",
    "#     return tokens\n",
    "\n",
    "# def split_religion(entry):\n",
    "#     \"\"\"\n",
    "#     Splits a religion entry into two parts:\n",
    "#       - primary religion (e.g., \"christianity\", \"atheism\", etc.)\n",
    "#       - secondary descriptor (e.g., \"very serious about it\")\n",
    "#     Uses a regex to look for \"and\" or \"but\" as a separator.\n",
    "#     If no separator is found, the entire entry is treated as the primary religion.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(entry):\n",
    "#         return (\"\", \"\")\n",
    "#     pattern = re.compile(r'^(.*?)\\s*(?:and|but)\\s*(.*)$', flags=re.IGNORECASE)\n",
    "#     match = pattern.match(entry)\n",
    "#     if match:\n",
    "#         primary = match.group(1).strip().lower()\n",
    "#         seriousness = match.group(2).strip().lower()\n",
    "#         return primary, seriousness\n",
    "#     else:\n",
    "#         return entry.strip().lower(), \"\"\n",
    "\n",
    "# def apply_religion_split(x):\n",
    "#     \"\"\"\n",
    "#     Applies split_religion and returns a pandas Series.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(x):\n",
    "#         return pd.Series([\"\", \"\"])\n",
    "#     else:\n",
    "#         return pd.Series(split_religion(x))\n",
    "\n",
    "# def split_sign(entry):\n",
    "#     \"\"\"\n",
    "#     Splits the 'sign' column into two parts:\n",
    "#       - sign_clean: the zodiac sign (e.g., \"pisces\", \"aries\", etc.)\n",
    "#       - sign_importance: an optional descriptor (e.g., \"but it doesn’t matter\")\n",
    "#     Uses a regex to look for \"and\" or \"but\" as a separator.\n",
    "#     Also decodes HTML entities, normalizes apostrophes, and strips extra spaces.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(entry):\n",
    "#         return \"\", \"\"\n",
    "#     # Decode HTML entities and normalize\n",
    "#     entry = html.unescape(entry.lower().replace(\"’\", \"'\"))\n",
    "#     pattern = re.compile(r'^(.*?)\\s*(?:but|and)\\s*(.*)$', flags=re.IGNORECASE)\n",
    "#     match = pattern.match(entry)\n",
    "#     if match:\n",
    "#         sign = match.group(1).strip()\n",
    "#         importance = match.group(2).strip()\n",
    "#         # Remove extraneous phrases if needed\n",
    "#         if \"doesn't matter\" in importance or \"fun to think about\" in importance:\n",
    "#             importance = \"\"\n",
    "#         if importance in [\"it's\", \"its\"]:\n",
    "#             importance = \"\"\n",
    "#         return sign, importance\n",
    "#     else:\n",
    "#         return entry.strip(), \"\"\n",
    "\n",
    "# def clean_pets(entry):\n",
    "#     \"\"\"\n",
    "#     Cleans the 'pets' column.\n",
    "#     Splits the entry on commas and the word \"and\" to extract individual pet descriptors.\n",
    "#     Returns a list of cleaned pet tokens.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(entry):\n",
    "#         return []\n",
    "#     entry = entry.lower()\n",
    "#     parts = re.split(r',', entry)\n",
    "#     tokens = []\n",
    "#     for part in parts:\n",
    "#         subparts = re.split(r'\\s+and\\s+', part)\n",
    "#         for token in subparts:\n",
    "#             token_clean = token.strip()\n",
    "#             if token_clean:\n",
    "#                 tokens.append(token_clean)\n",
    "#     return tokens\n",
    "\n",
    "# def clean_generic(entry):\n",
    "#     \"\"\"\n",
    "#     Generic cleaning for text:\n",
    "#     Decodes HTML entities and strips whitespace.\n",
    "#     If the entry is not a string, it is returned unchanged.\n",
    "#     \"\"\"\n",
    "#     if pd.isnull(entry):\n",
    "#         return entry\n",
    "#     if isinstance(entry, str):\n",
    "#         return html.unescape(entry).strip()\n",
    "#     return entry\n",
    "\n",
    "# # ---------------------------\n",
    "# # Create a New Cleaned DataFrame\n",
    "# # ---------------------------\n",
    "\n",
    "# # Start by making a copy of the original DataFrame.\n",
    "# new_df = df.copy()\n",
    "\n",
    "# # --- Process columns with special/multiple values ---\n",
    "\n",
    "# # Process 'speaks': convert each entry to a list of cleaned language tokens.\n",
    "# if 'speaks' in new_df.columns:\n",
    "#     new_df['speaks'] = new_df['speaks'].apply(lambda x: clean_speaks(x) if pd.notnull(x) else [])\n",
    "\n",
    "# # Process 'ethnicity': convert each entry to a list of cleaned ethnicity tokens.\n",
    "# if 'ethnicity' in new_df.columns:\n",
    "#     new_df['ethnicity'] = new_df['ethnicity'].apply(lambda x: clean_ethnicity(x) if pd.notnull(x) else [])\n",
    "\n",
    "# # Process 'job': convert each entry to a list of cleaned job tokens.\n",
    "# if 'job' in new_df.columns:\n",
    "#     new_df['job'] = new_df['job'].apply(lambda x: clean_job(x) if pd.notnull(x) else [])\n",
    "\n",
    "# # Process 'religion': create two new columns 'religion_primary' and 'religion_seriousness'\n",
    "# if 'religion' in new_df.columns:\n",
    "#     religion_split = new_df['religion'].apply(apply_religion_split)\n",
    "#     new_df['religion_primary'] = religion_split[0]\n",
    "#     new_df['religion_seriousness'] = religion_split[1]\n",
    "#     # Optionally, also clean the original 'religion' column\n",
    "#     new_df['religion'] = new_df['religion'].apply(lambda x: clean_generic(x))\n",
    "\n",
    "# # Process 'sign': create two new columns 'sign_clean' and 'sign_importance'\n",
    "# if 'sign' in new_df.columns:\n",
    "#     sign_split = new_df['sign'].apply(lambda x: pd.Series(split_sign(x)) if pd.notnull(x) else pd.Series([\"\", \"\"]))\n",
    "#     new_df['sign_clean'] = sign_split[0]\n",
    "#     new_df['sign_importance'] = sign_split[1]\n",
    "#     # Optionally, also clean the original 'sign' column\n",
    "#     new_df['sign'] = new_df['sign'].apply(lambda x: clean_generic(x))\n",
    "\n",
    "# # Process 'pets': convert each entry to a list of cleaned pet tokens.\n",
    "# if 'pets' in new_df.columns:\n",
    "#     new_df['pets'] = new_df['pets'].apply(lambda x: clean_pets(x) if pd.notnull(x) else [])\n",
    "\n",
    "# # --- Process other text columns ---\n",
    "# # Note: 'income' is purposefully excluded so that it is left as-is.\n",
    "# columns_to_clean = ['age', 'last_online', 'location'] + [f\"essay{i}\" for i in range(10)]\n",
    "# for col in columns_to_clean:\n",
    "#     if col in new_df.columns:\n",
    "#         new_df[col] = new_df[col].apply(clean_generic)\n",
    "\n",
    "# # As an extra step, clean any other object-type columns that haven’t already been processed.\n",
    "# for col in new_df.select_dtypes(include=['object']).columns:\n",
    "#     if col in ['speaks', 'ethnicity', 'job', 'religion', 'sign', 'pets'] or col.startswith('essay'):\n",
    "#         continue\n",
    "#     new_df[col] = new_df[col].apply(clean_generic)\n",
    "\n",
    "# # --- Combine Essays ---\n",
    "# # Combine essay columns into a single \"essays\" column and then drop the individual essay columns.\n",
    "# essay_cols = [f\"essay{i}\" for i in range(10) if f\"essay{i}\" in new_df.columns]\n",
    "# if essay_cols:\n",
    "#     new_df['essays'] = new_df[essay_cols].apply(\n",
    "#         lambda row: ' '.join([str(val) for val in row if pd.notnull(val) and str(val).strip() != '']),\n",
    "#         axis=1\n",
    "#     )\n",
    "#     new_df.drop(columns=essay_cols, inplace=True)\n",
    "\n",
    "# # --- Drop Old Columns After Splitting ---\n",
    "# # Remove the original 'religion' and 'sign' columns now that we have split versions.\n",
    "# for col in ['religion', 'sign']:\n",
    "#     if col in new_df.columns:\n",
    "#         new_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# # --- Optional: Reorder Columns ---\n",
    "# # For instance, you might want the new split columns to appear in the order you prefer.\n",
    "# ordered_cols = []\n",
    "# for col in df.columns:\n",
    "#     # For the religion column, add the split columns instead.\n",
    "#     if col == 'religion':\n",
    "#         if 'religion_primary' in new_df.columns:\n",
    "#             ordered_cols.append('religion_primary')\n",
    "#         if 'religion_seriousness' in new_df.columns:\n",
    "#             ordered_cols.append('religion_seriousness')\n",
    "#     # For the sign column, add the split columns instead.\n",
    "#     elif col == 'sign':\n",
    "#         if 'sign_clean' in new_df.columns:\n",
    "#             ordered_cols.append('sign_clean')\n",
    "#         if 'sign_importance' in new_df.columns:\n",
    "#             ordered_cols.append('sign_importance')\n",
    "#     elif col in new_df.columns:\n",
    "#         ordered_cols.append(col)\n",
    "# # Append any remaining columns that were added but not yet ordered.\n",
    "# for col in new_df.columns:\n",
    "#     if col not in ordered_cols:\n",
    "#         ordered_cols.append(col)\n",
    "# new_df = new_df[ordered_cols]\n",
    "\n",
    "# rename_columns = {\n",
    "#     'religion_primary': 'religion',\n",
    "#     'religion_seriousness': 'religion_serious',\n",
    "#     'sign_clean': 'sign',\n",
    "#     'sign_importance': 'sign_note'\n",
    "# }\n",
    "# new_df.rename(columns=rename_columns, inplace=True)\n",
    "# # ---------------------------\n",
    "# # Finished: new_df is the cleaned DataFrame.\n",
    "# # ---------------------------\n",
    "# print(\"DataFrame cleaning complete. Here's a preview of the cleaned DataFrame:\")\n",
    "# print(new_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame cleaning complete. Here's a preview of the cleaned DataFrame:\n",
      "   age     status sex orientation       body_type               diet  \\\n",
      "0   22     single   m    straight  a little extra  strictly anything   \n",
      "1   35     single   m    straight         average       mostly other   \n",
      "2   38  available   m    straight            thin           anything   \n",
      "3   23     single   m    straight            thin         vegetarian   \n",
      "4   29     single   m    straight        athletic                NaN   \n",
      "\n",
      "     drinks      drugs                          education  \\\n",
      "0  socially      never      working on college/university   \n",
      "1     often  sometimes              working on space camp   \n",
      "2  socially        NaN     graduated from masters program   \n",
      "3  socially        NaN      working on college/university   \n",
      "4  socially      never  graduated from college/university   \n",
      "\n",
      "               ethnicity  ...                 city  \\\n",
      "0         [asian, white]  ...  south san francisco   \n",
      "1                [white]  ...              oakland   \n",
      "2                     []  ...        san francisco   \n",
      "3                [white]  ...             berkeley   \n",
      "4  [asian, black, other]  ...        san francisco   \n",
      "\n",
      "                                offspring                      pets  \\\n",
      "0  doesn't have kids, but might want them  [likes dogs, likes cats]   \n",
      "1  doesn't have kids, but might want them  [likes dogs, likes cats]   \n",
      "2                                     NaN                [has cats]   \n",
      "3                       doesn't want kids              [likes cats]   \n",
      "4                                     NaN  [likes dogs, likes cats]   \n",
      "\n",
      "      religion          religion_serious      sign          sign_note  \\\n",
      "0  agnosticism     very serious about it    gemini                      \n",
      "1  agnosticism  not too serious about it    cancer                      \n",
      "2                                           pisces  it doesn’t matter   \n",
      "3                                           pisces                      \n",
      "4                                         aquarius                      \n",
      "\n",
      "      smokes                      speaks  \\\n",
      "0  sometimes                   [english]   \n",
      "1         no  [english, spanish, french]   \n",
      "2         no      [english, french, c++]   \n",
      "3         no           [english, german]   \n",
      "4         no                   [english]   \n",
      "\n",
      "                                              essays  \n",
      "0  about me:  i would love to think that i was so...  \n",
      "1  i am a chef: this is what that means. 1. i am ...  \n",
      "2  i'm not ashamed of much, but writing public te...  \n",
      "3  i work in a library and go to school. . . read...  \n",
      "4  hey how's it going? currently vague on the pro...  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Assume your DataFrame is already loaded (for example):\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# Helper Cleaning Functions\n",
    "# ---------------------------\n",
    "\n",
    "def clean_speaks(entry):\n",
    "    if pd.isnull(entry):\n",
    "        return []\n",
    "    languages = entry.split(',')\n",
    "    cleaned = []\n",
    "    for lang in languages:\n",
    "        lang_clean = re.sub(r'\\s*\\(.*\\)', '', lang).strip().lower()\n",
    "        if lang_clean:\n",
    "            cleaned.append(lang_clean)\n",
    "    return cleaned\n",
    "\n",
    "def clean_ethnicity(entry):\n",
    "    if pd.isnull(entry):\n",
    "        return []\n",
    "    tokens = []\n",
    "    for part in entry.split(','):\n",
    "        for token in part.split('/'):\n",
    "            token_clean = token.strip().lower()\n",
    "            if token_clean:\n",
    "                tokens.append(token_clean)\n",
    "    return tokens\n",
    "\n",
    "def clean_job(entry):\n",
    "    if pd.isnull(entry):\n",
    "        return []\n",
    "    tokens = []\n",
    "    for part in entry.split(','):\n",
    "        for token in part.split('/'):\n",
    "            token_clean = token.strip().lower()\n",
    "            if token_clean:\n",
    "                tokens.append(token_clean)\n",
    "    return tokens\n",
    "\n",
    "def split_religion(entry):\n",
    "    if pd.isnull(entry):\n",
    "        return (\"\", \"\")\n",
    "    pattern = re.compile(r'^(.*?)\\s*(?:and|but)\\s*(.*)$', flags=re.IGNORECASE)\n",
    "    match = pattern.match(entry)\n",
    "    if match:\n",
    "        primary = match.group(1).strip().lower()\n",
    "        seriousness = match.group(2).strip().lower()\n",
    "        return primary, seriousness\n",
    "    else:\n",
    "        return entry.strip().lower(), \"\"\n",
    "\n",
    "def apply_religion_split(x):\n",
    "    if pd.isnull(x):\n",
    "        return pd.Series([\"\", \"\"])\n",
    "    else:\n",
    "        return pd.Series(split_religion(x))\n",
    "\n",
    "def split_sign(entry):\n",
    "    if pd.isnull(entry):\n",
    "        return \"\", \"\"\n",
    "    entry = html.unescape(entry.lower().replace(\"’\", \"'\"))\n",
    "    pattern = re.compile(r'^(.*?)\\s*(?:but|and)\\s*(.*)$', flags=re.IGNORECASE)\n",
    "    match = pattern.match(entry)\n",
    "    if match:\n",
    "        sign = match.group(1).strip()\n",
    "        importance = match.group(2).strip()\n",
    "        if \"doesn't matter\" in importance or \"fun to think about\" in importance:\n",
    "            importance = \"\"\n",
    "        if importance in [\"it's\", \"its\"]:\n",
    "            importance = \"\"\n",
    "        return sign, importance\n",
    "    else:\n",
    "        return entry.strip(), \"\"\n",
    "\n",
    "def clean_pets(entry):\n",
    "    if pd.isnull(entry):\n",
    "        return []\n",
    "    entry = entry.lower()\n",
    "    parts = re.split(r',', entry)\n",
    "    tokens = []\n",
    "    for part in parts:\n",
    "        subparts = re.split(r'\\s+and\\s+', part)\n",
    "        for token in subparts:\n",
    "            token_clean = token.strip()\n",
    "            if token_clean:\n",
    "                tokens.append(token_clean)\n",
    "    return tokens\n",
    "\n",
    "def clean_generic(entry):\n",
    "    if pd.isnull(entry):\n",
    "        return entry\n",
    "    if isinstance(entry, str):\n",
    "        return html.unescape(entry).strip()\n",
    "    return entry\n",
    "\n",
    "# ---------------------------\n",
    "# Split Location into Country and City\n",
    "# ---------------------------\n",
    "\n",
    "def split_location(entry):\n",
    "    \"\"\"\n",
    "    Splits a location string into city and country/state.\n",
    "    Assumes format \"city, country/state\".\n",
    "    If no comma is found, treats the entire string as city and country is empty.\n",
    "    \"\"\"\n",
    "    if pd.isnull(entry):\n",
    "        return pd.Series([\"\", \"\"])\n",
    "    parts = [part.strip() for part in entry.split(',')]\n",
    "    if len(parts) >= 2:\n",
    "        country = parts[-1]\n",
    "        city = \", \".join(parts[:-1])\n",
    "    else:\n",
    "        city = parts[0]\n",
    "        country = \"\"\n",
    "    return pd.Series([country, city])\n",
    "\n",
    "# ---------------------------\n",
    "# Create a New Cleaned DataFrame\n",
    "# ---------------------------\n",
    "\n",
    "new_df = df.copy()\n",
    "\n",
    "# --- Process columns with special/multiple values ---\n",
    "\n",
    "if 'speaks' in new_df.columns:\n",
    "    new_df['speaks'] = new_df['speaks'].apply(lambda x: clean_speaks(x) if pd.notnull(x) else [])\n",
    "\n",
    "if 'ethnicity' in new_df.columns:\n",
    "    new_df['ethnicity'] = new_df['ethnicity'].apply(lambda x: clean_ethnicity(x) if pd.notnull(x) else [])\n",
    "\n",
    "if 'job' in new_df.columns:\n",
    "    new_df['job'] = new_df['job'].apply(lambda x: clean_job(x) if pd.notnull(x) else [])\n",
    "\n",
    "if 'religion' in new_df.columns:\n",
    "    religion_split = new_df['religion'].apply(apply_religion_split)\n",
    "    new_df['religion_primary'] = religion_split[0]\n",
    "    new_df['religion_seriousness'] = religion_split[1]\n",
    "    new_df['religion'] = new_df['religion'].apply(lambda x: clean_generic(x))\n",
    "\n",
    "if 'sign' in new_df.columns:\n",
    "    sign_split = new_df['sign'].apply(lambda x: pd.Series(split_sign(x)) if pd.notnull(x) else pd.Series([\"\", \"\"]))\n",
    "    new_df['sign_clean'] = sign_split[0]\n",
    "    new_df['sign_importance'] = sign_split[1]\n",
    "    new_df['sign'] = new_df['sign'].apply(lambda x: clean_generic(x))\n",
    "\n",
    "if 'pets' in new_df.columns:\n",
    "    new_df['pets'] = new_df['pets'].apply(lambda x: clean_pets(x) if pd.notnull(x) else [])\n",
    "\n",
    "# Process text columns\n",
    "columns_to_clean = ['age', 'last_online', 'location'] + [f\"essay{i}\" for i in range(10)]\n",
    "for col in columns_to_clean:\n",
    "    if col in new_df.columns:\n",
    "        new_df[col] = new_df[col].apply(clean_generic)\n",
    "\n",
    "# Process other object-type columns\n",
    "for col in new_df.select_dtypes(include=['object']).columns:\n",
    "    if col in ['speaks', 'ethnicity', 'job', 'religion', 'sign', 'pets'] or col.startswith('essay'):\n",
    "        continue\n",
    "    new_df[col] = new_df[col].apply(clean_generic)\n",
    "\n",
    "# --- Split Location into Country and City ---\n",
    "if 'location' in new_df.columns:\n",
    "    new_df[['country', 'city']] = new_df['location'].apply(split_location)\n",
    "    new_df.drop(columns=['location'], inplace=True)\n",
    "\n",
    "# --- Combine Essays ---\n",
    "essay_cols = [f\"essay{i}\" for i in range(10) if f\"essay{i}\" in new_df.columns]\n",
    "if essay_cols:\n",
    "    new_df['essays'] = new_df[essay_cols].apply(\n",
    "        lambda row: ' '.join([str(val) for val in row if pd.notnull(val) and str(val).strip() != '']),\n",
    "        axis=1\n",
    "    )\n",
    "    new_df.drop(columns=essay_cols, inplace=True)\n",
    "\n",
    "# --- Drop Old Columns After Splitting ---\n",
    "for col in ['religion', 'sign']:\n",
    "    if col in new_df.columns:\n",
    "        new_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# --- Reorder Columns ---\n",
    "ordered_cols = []\n",
    "for col in df.columns:\n",
    "    if col == 'religion':\n",
    "        if 'religion_primary' in new_df.columns:\n",
    "            ordered_cols.append('religion_primary')\n",
    "        if 'religion_seriousness' in new_df.columns:\n",
    "            ordered_cols.append('religion_seriousness')\n",
    "    elif col == 'sign':\n",
    "        if 'sign_clean' in new_df.columns:\n",
    "            ordered_cols.append('sign_clean')\n",
    "        if 'sign_importance' in new_df.columns:\n",
    "            ordered_cols.append('sign_importance')\n",
    "    elif col == 'location':\n",
    "        ordered_cols.extend(['country', 'city'])\n",
    "    elif col in new_df.columns:\n",
    "        ordered_cols.append(col)\n",
    "\n",
    "for col in new_df.columns:\n",
    "    if col not in ordered_cols:\n",
    "        ordered_cols.append(col)\n",
    "\n",
    "new_df = new_df[ordered_cols]\n",
    "\n",
    "# Rename columns\n",
    "rename_columns = {\n",
    "    'religion_primary': 'religion',\n",
    "    'religion_seriousness': 'religion_serious',\n",
    "    'sign_clean': 'sign',\n",
    "    'sign_importance': 'sign_note'\n",
    "}\n",
    "new_df.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Finished: new_df is the cleaned DataFrame.\n",
    "# ---------------------------\n",
    "print(\"DataFrame cleaning complete. Here's a preview of the cleaned DataFrame:\")\n",
    "print(new_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the cleaned DataFrame to a CSV file:\n",
    "new_df.to_csv(\"../data/okcupid_profiles_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options to show all rows and columns without truncation\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)  # Prevent line wrapping for better visibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               59946 non-null  int64  \n",
      " 1   status            59946 non-null  object \n",
      " 2   sex               59946 non-null  object \n",
      " 3   orientation       59946 non-null  object \n",
      " 4   body_type         54650 non-null  object \n",
      " 5   diet              35551 non-null  object \n",
      " 6   drinks            56961 non-null  object \n",
      " 7   drugs             45866 non-null  object \n",
      " 8   education         53318 non-null  object \n",
      " 9   ethnicity         59946 non-null  object \n",
      " 10  height            59943 non-null  float64\n",
      " 11  income            59946 non-null  int64  \n",
      " 12  job               59946 non-null  object \n",
      " 13  last_online       59946 non-null  object \n",
      " 14  country           59946 non-null  object \n",
      " 15  city              59946 non-null  object \n",
      " 16  offspring         24385 non-null  object \n",
      " 17  pets              59946 non-null  object \n",
      " 18  religion          59946 non-null  object \n",
      " 19  religion_serious  59946 non-null  object \n",
      " 20  sign              59946 non-null  object \n",
      " 21  sign_note         59946 non-null  object \n",
      " 22  smokes            54434 non-null  object \n",
      " 23  speaks            59946 non-null  object \n",
      " 24  essays            59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(22)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
