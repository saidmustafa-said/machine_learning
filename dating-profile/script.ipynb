{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Report for the okcupid_profile dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 1. Load the Dataset\n",
    "# -----------------------------\n",
    "file_path = '../data/okcupid_profiles.csv'  # Updated file path\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     status sex orientation       body_type               diet    drinks      drugs                          education            ethnicity  height  income                          job       last_online                         location                               offspring                       pets                                  religion                                sign     smokes                                             speaks                                             essay0                                             essay1                                             essay2                                             essay3                                             essay4                                             essay5                       essay6                                             essay7                                             essay8                                             essay9\n",
      "0   22     single   m    straight  a little extra  strictly anything  socially      never      working on college/university         asian, white    75.0      -1               transportation  2012-06-28-20-30  south san francisco, california  doesn't have kids, but might want them  likes dogs and likes cats     agnosticism and very serious about it                              gemini  sometimes                                            english  about me:  i would love to think that i was so...  currently working as an international agent fo...  making people laugh. ranting about a good salt...  the way i look. i am a six foot half asian, ha...  books: absurdistan, the republic, of mice and ...                  food. water. cell phone. shelter.  duality and humorous things  trying to find someone to hang out with. i am ...  i am new to california and looking for someone...  you want to be swept off your feet! you are ti...\n",
      "1   35     single   m    straight         average       mostly other     often  sometimes              working on space camp                white    70.0   80000         hospitality / travel  2012-06-29-21-41              oakland, california  doesn't have kids, but might want them  likes dogs and likes cats  agnosticism but not too serious about it                              cancer         no  english (fluently), spanish (poorly), french (...  i am a chef: this is what that means. 1. i am ...  dedicating everyday to being an unbelievable b...  being silly. having ridiculous amonts of fun w...                                                NaN  i am die hard christopher moore fan. i don't r...  delicious porkness in all of its glories. my b...                          NaN                                                NaN  i am very open and will share just about anyth...                                                NaN\n",
      "2   38  available   m    straight            thin           anything  socially        NaN     graduated from masters program                  NaN    68.0      -1                          NaN  2012-06-27-09-10        san francisco, california                                     NaN                   has cats                                       NaN  pisces but it doesn&rsquo;t matter         no                               english, french, c++  i'm not ashamed of much, but writing public te...  i make nerdy software for musicians, artists, ...  improvising in different contexts. alternating...  my large jaw and large glasses are the physica...  okay this is where the cultural matrix gets so...  movement conversation creation contemplation t...                          NaN  viewing. listening. dancing. talking. drinking...  when i was five years old, i was known as \"the...  you are bright, open, intense, silly, ironic, ...\n",
      "3   23     single   m    straight            thin         vegetarian  socially        NaN      working on college/university                white    71.0   20000                      student  2012-06-28-14-22             berkeley, california                       doesn't want kids                 likes cats                                       NaN                              pisces         no                           english, german (poorly)          i work in a library and go to school. . .          reading things written by old dead people  playing synthesizers and organizing books acco...                  socially awkward but i do my best  bataille, celine, beckett. . . lynch, jarmusch...                                                NaN   cats and german philosophy                                                NaN                                                NaN                              you feel so inclined.\n",
      "4   29     single   m    straight        athletic                NaN  socially      never  graduated from college/university  asian, black, other    66.0      -1  artistic / musical / writer  2012-06-27-21-26        san francisco, california                                     NaN  likes dogs and likes cats                                       NaN                            aquarius         no                                            english  hey how's it going? currently vague on the pro...                         work work work work + play  creating imagery to look at: http://bagsbrown....            i smile a lot and my inquisitive nature  music: bands, rappers, musicians at the moment...                                                NaN                          NaN                                                NaN                                                NaN                                                NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet    drinks      drugs                          education            ethnicity  height  income                          job       last_online                         location                               offspring                       pets                                  religion                                sign     smokes                                             speaks                                             essay0                                             essay1                                             essay2                                             essay3                                             essay4                                             essay5                       essay6                                             essay7                                             essay8                                             essay9\n",
       "0   22     single   m    straight  a little extra  strictly anything  socially      never      working on college/university         asian, white    75.0      -1               transportation  2012-06-28-20-30  south san francisco, california  doesn't have kids, but might want them  likes dogs and likes cats     agnosticism and very serious about it                              gemini  sometimes                                            english  about me:  i would love to think that i was so...  currently working as an international agent fo...  making people laugh. ranting about a good salt...  the way i look. i am a six foot half asian, ha...  books: absurdistan, the republic, of mice and ...                  food. water. cell phone. shelter.  duality and humorous things  trying to find someone to hang out with. i am ...  i am new to california and looking for someone...  you want to be swept off your feet! you are ti...\n",
       "1   35     single   m    straight         average       mostly other     often  sometimes              working on space camp                white    70.0   80000         hospitality / travel  2012-06-29-21-41              oakland, california  doesn't have kids, but might want them  likes dogs and likes cats  agnosticism but not too serious about it                              cancer         no  english (fluently), spanish (poorly), french (...  i am a chef: this is what that means. 1. i am ...  dedicating everyday to being an unbelievable b...  being silly. having ridiculous amonts of fun w...                                                NaN  i am die hard christopher moore fan. i don't r...  delicious porkness in all of its glories. my b...                          NaN                                                NaN  i am very open and will share just about anyth...                                                NaN\n",
       "2   38  available   m    straight            thin           anything  socially        NaN     graduated from masters program                  NaN    68.0      -1                          NaN  2012-06-27-09-10        san francisco, california                                     NaN                   has cats                                       NaN  pisces but it doesn&rsquo;t matter         no                               english, french, c++  i'm not ashamed of much, but writing public te...  i make nerdy software for musicians, artists, ...  improvising in different contexts. alternating...  my large jaw and large glasses are the physica...  okay this is where the cultural matrix gets so...  movement conversation creation contemplation t...                          NaN  viewing. listening. dancing. talking. drinking...  when i was five years old, i was known as \"the...  you are bright, open, intense, silly, ironic, ...\n",
       "3   23     single   m    straight            thin         vegetarian  socially        NaN      working on college/university                white    71.0   20000                      student  2012-06-28-14-22             berkeley, california                       doesn't want kids                 likes cats                                       NaN                              pisces         no                           english, german (poorly)          i work in a library and go to school. . .          reading things written by old dead people  playing synthesizers and organizing books acco...                  socially awkward but i do my best  bataille, celine, beckett. . . lynch, jarmusch...                                                NaN   cats and german philosophy                                                NaN                                                NaN                              you feel so inclined.\n",
       "4   29     single   m    straight        athletic                NaN  socially      never  graduated from college/university  asian, black, other    66.0      -1  artistic / musical / writer  2012-06-27-21-26        san francisco, california                                     NaN  likes dogs and likes cats                                       NaN                            aquarius         no                                            english  hey how's it going? currently vague on the pro...                         work work work work + play  creating imagery to look at: http://bagsbrown....            i smile a lot and my inquisitive nature  music: bands, rappers, musicians at the moment...                                                NaN                          NaN                                                NaN                                                NaN                                                NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)  # Prevent line wrapping for better visibility\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      " 21  essay0       54458 non-null  object \n",
      " 22  essay1       52374 non-null  object \n",
      " 23  essay2       50308 non-null  object \n",
      " 24  essay3       48470 non-null  object \n",
      " 25  essay4       49409 non-null  object \n",
      " 26  essay5       49096 non-null  object \n",
      " 27  essay6       46175 non-null  object \n",
      " 28  essay7       47495 non-null  object \n",
      " 29  essay8       40721 non-null  object \n",
      " 30  essay9       47343 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: single, available, seeing someone, married, unknown\n",
      "sex: m, f\n",
      "orientation: straight, bisexual, gay\n",
      "body_type: a little extra, average, thin, athletic, fit, skinny, curvy, full figured, jacked, rather not say, used up, overweight\n",
      "diet: strictly anything, mostly other, anything, vegetarian, mostly anything, mostly vegetarian, strictly vegan, strictly vegetarian, mostly vegan, strictly other, mostly halal, other, vegan, mostly kosher, strictly halal, halal, strictly kosher, kosher\n",
      "drinks: socially, often, not at all, rarely, very often, desperately\n",
      "drugs: never, sometimes, often\n",
      "education: working on college/university, working on space camp, graduated from masters program, graduated from college/university, working on two-year college, graduated from high school, working on masters program, graduated from space camp, college/university, dropped out of space camp, graduated from ph.d program, graduated from law school, working on ph.d program, two-year college, graduated from two-year college, working on med school, dropped out of college/university, space camp, graduated from med school, dropped out of high school, working on high school, masters program, dropped out of ph.d program, dropped out of two-year college, dropped out of med school, high school, working on law school, law school, dropped out of masters program, ph.d program, dropped out of law school, med school\n",
      "ethnicity: asian, black, hispanic, indian, latin, middle eastern, native american, other, pacific islander, white\n",
      "height: 75.0, 70.0, 68.0, 71.0, 66.0, 67.0, 65.0, 72.0, 62.0, 64.0, 69.0, 73.0, 74.0, 60.0, 63.0, 76.0, 61.0, 78.0, 79.0, 59.0, 80.0, 91.0, 83.0, 77.0, 58.0, 56.0, 95.0, 57.0, 87.0, 81.0, 36.0, 43.0, 52.0, 55.0, 53.0, 93.0, 8.0, 54.0, 82.0, 3.0, 86.0, 42.0, 84.0, 94.0, 50.0, 6.0, 47.0, 49.0, 48.0, 90.0, 88.0, 37.0, 9.0, 51.0, 1.0, 92.0, 26.0, 85.0, 89.0, 4.0\n",
      "job: academia, administrative, artistic, banking, biz dev, clerical, computer, construction, craftsmanship, education, engineering, entertainment, executive, financial, government, hardware, health, hospitality, law, legal services, management, marketing, media, medicine, military, musical, other, political, rather not say, real estate, retired, sales, science, software, student, tech, transportation, travel, unemployed, writer\n",
      "offspring: doesn't have kids, but might want them, doesn't want kids, doesn't have kids, but wants them, doesn't have kids, wants kids, has a kid, has kids, doesn't have kids, and doesn't want any, has kids, but doesn't want more, has a kid, but doesn't want more, has a kid, and wants more, has kids, and might want more, might want kids, has a kid, and might want more, has kids, and wants more\n",
      "pets: likes dogs and likes cats, has cats, likes cats, has dogs and likes cats, likes dogs and has cats, likes dogs and dislikes cats, has dogs, has dogs and dislikes cats, likes dogs, has dogs and has cats, dislikes dogs and has cats, dislikes dogs and dislikes cats, dislikes cats, dislikes dogs and likes cats, dislikes dogs\n",
      "religion_primary: , agnosticism, atheism, buddhism, catholicism, christianity, hinduism, islam, judaism, other\n",
      "religion_seriousness: , laughing about it, not too serious about it, somewhat serious about it, very serious about it\n",
      "sign: gemini, cancer, pisces but it doesn&rsquo;t matter, pisces, aquarius, taurus, virgo, sagittarius, gemini but it doesn&rsquo;t matter, cancer but it doesn&rsquo;t matter, leo but it doesn&rsquo;t matter, aquarius but it doesn&rsquo;t matter, aries and it&rsquo;s fun to think about, libra but it doesn&rsquo;t matter, pisces and it&rsquo;s fun to think about, libra, taurus but it doesn&rsquo;t matter, sagittarius but it doesn&rsquo;t matter, scorpio and it matters a lot, gemini and it&rsquo;s fun to think about, leo and it&rsquo;s fun to think about, cancer and it&rsquo;s fun to think about, libra and it&rsquo;s fun to think about, aquarius and it&rsquo;s fun to think about, virgo but it doesn&rsquo;t matter, scorpio and it&rsquo;s fun to think about, capricorn but it doesn&rsquo;t matter, scorpio, capricorn and it&rsquo;s fun to think about, leo, aries but it doesn&rsquo;t matter, aries, scorpio but it doesn&rsquo;t matter, sagittarius and it&rsquo;s fun to think about, libra and it matters a lot, taurus and it&rsquo;s fun to think about, leo and it matters a lot, virgo and it&rsquo;s fun to think about, cancer and it matters a lot, capricorn, pisces and it matters a lot, aries and it matters a lot, capricorn and it matters a lot, aquarius and it matters a lot, sagittarius and it matters a lot, gemini and it matters a lot, taurus and it matters a lot, virgo and it matters a lot\n",
      "smokes: sometimes, no, when drinking, yes, trying to quit\n",
      "speaks: afrikaans, albanian, ancient greek, arabic, armenian, basque, belarusan, bengali, breton, bulgarian, c++, catalan, cebuano, chechen, chinese, croatian, czech, danish, dutch, english, esperanto, estonian, farsi, finnish, french, frisian, georgian, german, greek, gujarati, hawaiian, hebrew, hindi, hungarian, icelandic, ilongo, indonesian, irish, italian, japanese, khmer, korean, latin, latvian, lisp, lithuanian, malay, maori, mongolian, norwegian, occitan, other, persian, polish, portuguese, romanian, rotuman, russian, sanskrit, sardinian, serbian, sign language, slovak, slovenian, spanish, swahili, swedish, tagalog, tamil, thai, tibetan, turkish, ukrainian, urdu, vietnamese, welsh, yiddish\n",
      "sign_primary: gemini, cancer, pisces, aquarius, taurus, virgo, sagittarius, leo, , aries, libra, scorpio, capricorn\n",
      "sign_importance: , it doesn&rsquo;t matter, it&rsquo;s fun to think about, it matters a lot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Assume df is already defined (e.g., loaded via pd.read_csv(\"your_data.csv\"))\n",
    "\n",
    "# Define columns to skip because they have too many unique values\n",
    "skip_cols = ['age', 'income', 'last_online', 'location'] + [f\"essay{i}\" for i in range(10)]\n",
    "\n",
    "# ---------------------------\n",
    "# Helper functions for cleaning\n",
    "# ---------------------------\n",
    "\n",
    "def clean_speaks(entry):\n",
    "    \"\"\"\n",
    "    Cleans an entry from the 'speaks' column by splitting on commas,\n",
    "    removing any parenthetical information, stripping extra spaces,\n",
    "    and lowercasing the language names.\n",
    "    Returns a list of cleaned language tokens.\n",
    "    \"\"\"\n",
    "    languages = entry.split(',')\n",
    "    cleaned = []\n",
    "    for lang in languages:\n",
    "        # Remove parenthetical remarks (e.g., \"english (fluently)\" -> \"english\")\n",
    "        lang_clean = re.sub(r'\\s*\\(.*\\)', '', lang).strip().lower()\n",
    "        if lang_clean:\n",
    "            cleaned.append(lang_clean)\n",
    "    return cleaned\n",
    "\n",
    "def clean_ethnicity(entry):\n",
    "    \"\"\"\n",
    "    Cleans an entry from the 'ethnicity' column.\n",
    "    Splits on commas and also on forward-slashes if present,\n",
    "    strips extra spaces, and lowercases the tokens.\n",
    "    Returns a list of cleaned ethnicity tokens.\n",
    "    \"\"\"\n",
    "    # First split on commas, then further split each piece on '/'\n",
    "    tokens = []\n",
    "    for part in entry.split(','):\n",
    "        for token in part.split('/'):\n",
    "            token_clean = token.strip().lower()\n",
    "            if token_clean:\n",
    "                tokens.append(token_clean)\n",
    "    return tokens\n",
    "\n",
    "def clean_job(entry):\n",
    "    \"\"\"\n",
    "    Cleans an entry from the 'job' column.\n",
    "    Many job entries include multiple values separated by commas and/or '/'\n",
    "    (for example, \"artistic / musical / writer\" or \"hospitality / travel\").\n",
    "    This function splits the string on commas and then on '/' to extract individual tokens,\n",
    "    strips extra whitespace, and lowercases the result.\n",
    "    Returns a list of cleaned job tokens.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    # Split by comma first (if there are multiple entries)\n",
    "    for part in entry.split(','):\n",
    "        # Then split further by '/'\n",
    "        for sub in part.split('/'):\n",
    "            token = sub.strip().lower()\n",
    "            if token:\n",
    "                tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "def split_religion(entry):\n",
    "    \"\"\"\n",
    "    Splits a religion entry into two parts:\n",
    "      - primary religion (e.g. \"christianity\", \"atheism\", etc.)\n",
    "      - secondary descriptor (e.g. \"very serious about it\", \"but not too serious about it\")\n",
    "      \n",
    "    It uses a regular expression to look for \"and\" or \"but\" as a separator.\n",
    "    If no separator is found, the entire entry is treated as the primary religion.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'^(.*?)\\s*(?:and|but)\\s*(.*)$', flags=re.IGNORECASE)\n",
    "    match = pattern.match(entry)\n",
    "    if match:\n",
    "        primary = match.group(1).strip().lower()\n",
    "        seriousness = match.group(2).strip().lower()\n",
    "        return primary, seriousness\n",
    "    else:\n",
    "        return entry.strip().lower(), \"\"\n",
    "\n",
    "def apply_religion_split(x):\n",
    "    \"\"\"\n",
    "    Helper to return a pandas Series for the new religion columns.\n",
    "    \"\"\"\n",
    "    if pd.isnull(x):\n",
    "        return pd.Series([\"\", \"\"])\n",
    "    else:\n",
    "        return pd.Series(split_religion(x))\n",
    "\n",
    "# -------------------------------------------\n",
    "# Create new columns by splitting \"religion\"\n",
    "# -------------------------------------------\n",
    "df[['religion_primary', 'religion_seriousness']] = df['religion'].apply(apply_religion_split)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Build the unique summary string for the DataFrame\n",
    "# -------------------------------------------------\n",
    "unique_summary = \"\"\n",
    "\n",
    "for col in df.columns:\n",
    "    # Skip columns with too many unique values or the newly created religion columns\n",
    "    if col in skip_cols or col in ['religion_primary', 'religion_seriousness']:\n",
    "        continue\n",
    "\n",
    "    # Special cleaning for the \"speaks\" column\n",
    "    if col == 'speaks':\n",
    "        unique_set = set()\n",
    "        for entry in df['speaks'].dropna():\n",
    "            cleaned_languages = clean_speaks(entry)\n",
    "            unique_set.update(cleaned_languages)\n",
    "        unique_str = \", \".join(sorted(unique_set))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "\n",
    "    # Special cleaning for the \"ethnicity\" column\n",
    "    elif col == 'ethnicity':\n",
    "        unique_set = set()\n",
    "        for entry in df['ethnicity'].dropna():\n",
    "            cleaned_ethnicities = clean_ethnicity(entry)\n",
    "            unique_set.update(cleaned_ethnicities)\n",
    "        unique_str = \", \".join(sorted(unique_set))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "    \n",
    "    # Special cleaning for the \"job\" column\n",
    "    elif col == 'job':\n",
    "        unique_set = set()\n",
    "        for entry in df['job'].dropna():\n",
    "            cleaned_jobs = clean_job(entry)\n",
    "            unique_set.update(cleaned_jobs)\n",
    "        unique_str = \", \".join(sorted(unique_set))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "\n",
    "    # For the raw \"religion\" column, instead list the two new columns\n",
    "    elif col == 'religion':\n",
    "        unique_primary = df['religion_primary'].dropna().unique()\n",
    "        unique_seriousness = df['religion_seriousness'].dropna().unique()\n",
    "        unique_summary += f\"religion_primary: {', '.join(sorted(unique_primary))}\\n\"\n",
    "        unique_summary += f\"religion_seriousness: {', '.join(sorted(unique_seriousness))}\\n\"\n",
    "    \n",
    "    else:\n",
    "        # For all other columns, simply get the unique values\n",
    "        unique_values = df[col].dropna().unique()\n",
    "        unique_str = \", \".join(map(str, unique_values))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "\n",
    "# Print the final summary string\n",
    "print(unique_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: single, available, seeing someone, married, unknown\n",
      "sex: m, f\n",
      "orientation: straight, bisexual, gay\n",
      "body_type: a little extra, average, thin, athletic, fit, skinny, curvy, full figured, jacked, rather not say, used up, overweight\n",
      "diet: strictly anything, mostly other, anything, vegetarian, mostly anything, mostly vegetarian, strictly vegan, strictly vegetarian, mostly vegan, strictly other, mostly halal, other, vegan, mostly kosher, strictly halal, halal, strictly kosher, kosher\n",
      "drinks: socially, often, not at all, rarely, very often, desperately\n",
      "drugs: never, sometimes, often\n",
      "education: working on college/university, working on space camp, graduated from masters program, graduated from college/university, working on two-year college, graduated from high school, working on masters program, graduated from space camp, college/university, dropped out of space camp, graduated from ph.d program, graduated from law school, working on ph.d program, two-year college, graduated from two-year college, working on med school, dropped out of college/university, space camp, graduated from med school, dropped out of high school, working on high school, masters program, dropped out of ph.d program, dropped out of two-year college, dropped out of med school, high school, working on law school, law school, dropped out of masters program, ph.d program, dropped out of law school, med school\n",
      "ethnicity: asian, black, hispanic, indian, latin, middle eastern, native american, other, pacific islander, white\n",
      "height: 75.0, 70.0, 68.0, 71.0, 66.0, 67.0, 65.0, 72.0, 62.0, 64.0, 69.0, 73.0, 74.0, 60.0, 63.0, 76.0, 61.0, 78.0, 79.0, 59.0, 80.0, 91.0, 83.0, 77.0, 58.0, 56.0, 95.0, 57.0, 87.0, 81.0, 36.0, 43.0, 52.0, 55.0, 53.0, 93.0, 8.0, 54.0, 82.0, 3.0, 86.0, 42.0, 84.0, 94.0, 50.0, 6.0, 47.0, 49.0, 48.0, 90.0, 88.0, 37.0, 9.0, 51.0, 1.0, 92.0, 26.0, 85.0, 89.0, 4.0\n",
      "job: academia, administrative, artistic, banking, biz dev, clerical, computer, construction, craftsmanship, education, engineering, entertainment, executive, financial, government, hardware, health, hospitality, law, legal services, management, marketing, media, medicine, military, musical, other, political, rather not say, real estate, retired, sales, science, software, student, tech, transportation, travel, unemployed, writer\n",
      "offspring: doesn't have kids, but might want them, doesn't want kids, doesn't have kids, but wants them, doesn't have kids, wants kids, has a kid, has kids, doesn't have kids, and doesn't want any, has kids, but doesn't want more, has a kid, but doesn't want more, has a kid, and wants more, has kids, and might want more, might want kids, has a kid, and might want more, has kids, and wants more\n",
      "pets: dislikes cats, dislikes dogs, has cats, has dogs, likes cats, likes dogs\n",
      "religion_primary: , agnosticism, atheism, buddhism, catholicism, christianity, hinduism, islam, judaism, other\n",
      "religion_seriousness: , laughing about it, not too serious about it, somewhat serious about it, very serious about it\n",
      "sign_clean: , aquarius, aries, cancer, capricorn, gemini, leo, libra, pisces, sagittarius, scorpio, taurus, virgo\n",
      "sign_importance: , it doesn&rsquo;t matter, it matters a lot\n",
      "smokes: sometimes, no, when drinking, yes, trying to quit\n",
      "speaks: afrikaans, albanian, ancient greek, arabic, armenian, basque, belarusan, bengali, breton, bulgarian, c++, catalan, cebuano, chechen, chinese, croatian, czech, danish, dutch, english, esperanto, estonian, farsi, finnish, french, frisian, georgian, german, greek, gujarati, hawaiian, hebrew, hindi, hungarian, icelandic, ilongo, indonesian, irish, italian, japanese, khmer, korean, latin, latvian, lisp, lithuanian, malay, maori, mongolian, norwegian, occitan, other, persian, polish, portuguese, romanian, rotuman, russian, sanskrit, sardinian, serbian, sign language, slovak, slovenian, spanish, swahili, swedish, tagalog, tamil, thai, tibetan, turkish, ukrainian, urdu, vietnamese, welsh, yiddish\n",
      "sign_primary: gemini, cancer, pisces, aquarius, taurus, virgo, sagittarius, leo, , aries, libra, scorpio, capricorn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Assume df is already defined (for example, via pd.read_csv(\"your_data.csv\"))\n",
    "\n",
    "# Define columns to skip because they have too many unique values\n",
    "skip_cols = ['age', 'income', 'last_online', 'location'] + [f\"essay{i}\" for i in range(10)]\n",
    "\n",
    "# ---------------------------\n",
    "# Helper functions for cleaning\n",
    "# ---------------------------\n",
    "\n",
    "def clean_speaks(entry):\n",
    "    \"\"\"\n",
    "    Cleans an entry from the 'speaks' column by splitting on commas,\n",
    "    removing any parenthetical information, stripping extra spaces,\n",
    "    and lowercasing the language names.\n",
    "    Returns a list of cleaned language tokens.\n",
    "    \"\"\"\n",
    "    languages = entry.split(',')\n",
    "    cleaned = []\n",
    "    for lang in languages:\n",
    "        lang_clean = re.sub(r'\\s*\\(.*\\)', '', lang).strip().lower()\n",
    "        if lang_clean:\n",
    "            cleaned.append(lang_clean)\n",
    "    return cleaned\n",
    "\n",
    "def clean_ethnicity(entry):\n",
    "    \"\"\"\n",
    "    Cleans an entry from the 'ethnicity' column by splitting on commas and forward-slashes,\n",
    "    then stripping extra spaces and lowercasing each token.\n",
    "    Returns a list of cleaned ethnicity tokens.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for part in entry.split(','):\n",
    "        for token in part.split('/'):\n",
    "            token_clean = token.strip().lower()\n",
    "            if token_clean:\n",
    "                tokens.append(token_clean)\n",
    "    return tokens\n",
    "\n",
    "def clean_job(entry):\n",
    "    \"\"\"\n",
    "    Cleans an entry from the 'job' column.\n",
    "    Splits on commas and forward-slashes to extract individual tokens,\n",
    "    then strips extra spaces and lowercases the result.\n",
    "    Returns a list of cleaned job tokens.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for part in entry.split(','):\n",
    "        for token in part.split('/'):\n",
    "            token_clean = token.strip().lower()\n",
    "            if token_clean:\n",
    "                tokens.append(token_clean)\n",
    "    return tokens\n",
    "\n",
    "def split_religion(entry):\n",
    "    \"\"\"\n",
    "    Splits a religion entry into two parts:\n",
    "      - primary religion (e.g., \"christianity\", \"atheism\", etc.)\n",
    "      - secondary descriptor (e.g., \"very serious about it\", \"but not too serious about it\")\n",
    "    Uses a regex to look for the words \"and\" or \"but\" as a separator.\n",
    "    If no separator is found, the whole entry is treated as the primary religion.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'^(.*?)\\s*(?:and|but)\\s*(.*)$', flags=re.IGNORECASE)\n",
    "    match = pattern.match(entry)\n",
    "    if match:\n",
    "        primary = match.group(1).strip().lower()\n",
    "        seriousness = match.group(2).strip().lower()\n",
    "        return primary, seriousness\n",
    "    else:\n",
    "        return entry.strip().lower(), \"\"\n",
    "\n",
    "def apply_religion_split(x):\n",
    "    \"\"\"\n",
    "    Applies the split_religion function and returns a pandas Series\n",
    "    for the new religion columns.\n",
    "    \"\"\"\n",
    "    if pd.isnull(x):\n",
    "        return pd.Series([\"\", \"\"])\n",
    "    else:\n",
    "        return pd.Series(split_religion(x))\n",
    "\n",
    "def split_sign(entry):\n",
    "    \"\"\"\n",
    "    Splits an entry from the 'sign' column into two parts:\n",
    "      - sign_clean: the zodiac sign (e.g., \"gemini\", \"aries\", etc.)\n",
    "      - sign_importance: an optional descriptor (e.g., \"fun to think about\")\n",
    "    The function uses a regex to look for the keywords \"but\" or \"and\" as a separator.\n",
    "    It also normalizes apostrophes and removes common extraneous phrases.\n",
    "    \"\"\"\n",
    "    if pd.isnull(entry):\n",
    "        return \"\", \"\"\n",
    "    # Normalize to lowercase and replace curly apostrophes with straight ones\n",
    "    entry = entry.lower().replace(\"’\", \"'\")\n",
    "    pattern = re.compile(r'^(.*?)\\s*(?:but|and)\\s*(.*)$', flags=re.IGNORECASE)\n",
    "    match = pattern.match(entry)\n",
    "    if match:\n",
    "        sign = match.group(1).strip()\n",
    "        importance = match.group(2).strip()\n",
    "        # Remove common extraneous phrases\n",
    "        if \"doesn't matter\" in importance or \"fun to think about\" in importance:\n",
    "            importance = \"\"\n",
    "        # Remove isolated \"it's\" or \"its\" if that is all that remains\n",
    "        if importance in [\"it's\", \"its\"]:\n",
    "            importance = \"\"\n",
    "        return sign, importance\n",
    "    else:\n",
    "        return entry.strip(), \"\"\n",
    "\n",
    "def clean_pets(entry):\n",
    "    \"\"\"\n",
    "    Cleans an entry from the 'pets' column.\n",
    "    Splits the entry on commas and the word \"and\" to extract individual pet descriptors.\n",
    "    For example, an entry like \"likes dogs and likes cats, has cats\" is split into:\n",
    "      - \"likes dogs\"\n",
    "      - \"likes cats\"\n",
    "      - \"has cats\"\n",
    "    Returns a list of cleaned pet tokens.\n",
    "    \"\"\"\n",
    "    if pd.isnull(entry):\n",
    "        return []\n",
    "    # Lowercase the entry\n",
    "    entry = entry.lower()\n",
    "    # First, split on commas\n",
    "    parts = re.split(r',', entry)\n",
    "    tokens = []\n",
    "    for part in parts:\n",
    "        # Further split on the word \"and\"\n",
    "        subparts = re.split(r'\\s+and\\s+', part)\n",
    "        for token in subparts:\n",
    "            token_clean = token.strip()\n",
    "            if token_clean:\n",
    "                tokens.append(token_clean)\n",
    "    return tokens\n",
    "\n",
    "# -------------------------------------------\n",
    "# Create new columns by splitting \"religion\"\n",
    "# -------------------------------------------\n",
    "df[['religion_primary', 'religion_seriousness']] = df['religion'].apply(apply_religion_split)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Create new columns by splitting \"sign\"\n",
    "# -------------------------------------------\n",
    "# The new columns will be named \"sign_clean\" and \"sign_importance\"\n",
    "df[['sign_clean', 'sign_importance']] = df['sign'].apply(\n",
    "    lambda x: pd.Series(split_sign(x)) if pd.notnull(x) else pd.Series([\"\", \"\"])\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Build the unique summary string for the DataFrame\n",
    "# -------------------------------------------------\n",
    "unique_summary = \"\"\n",
    "\n",
    "for col in df.columns:\n",
    "    # Skip columns with too many unique values and the new columns we created\n",
    "    if col in skip_cols or col in ['religion_primary', 'religion_seriousness', 'sign_clean', 'sign_importance']:\n",
    "        continue\n",
    "\n",
    "    # Special cleaning for the \"speaks\" column\n",
    "    if col == 'speaks':\n",
    "        unique_set = set()\n",
    "        for entry in df['speaks'].dropna():\n",
    "            cleaned_languages = clean_speaks(entry)\n",
    "            unique_set.update(cleaned_languages)\n",
    "        unique_str = \", \".join(sorted(unique_set))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "\n",
    "    # Special cleaning for the \"ethnicity\" column\n",
    "    elif col == 'ethnicity':\n",
    "        unique_set = set()\n",
    "        for entry in df['ethnicity'].dropna():\n",
    "            cleaned_ethnicities = clean_ethnicity(entry)\n",
    "            unique_set.update(cleaned_ethnicities)\n",
    "        unique_str = \", \".join(sorted(unique_set))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "    \n",
    "    # Special cleaning for the \"job\" column\n",
    "    elif col == 'job':\n",
    "        unique_set = set()\n",
    "        for entry in df['job'].dropna():\n",
    "            cleaned_jobs = clean_job(entry)\n",
    "            unique_set.update(cleaned_jobs)\n",
    "        unique_str = \", \".join(sorted(unique_set))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "\n",
    "    # For the raw \"religion\" column, output the two new religion columns instead\n",
    "    elif col == 'religion':\n",
    "        unique_primary = df['religion_primary'].dropna().unique()\n",
    "        unique_seriousness = df['religion_seriousness'].dropna().unique()\n",
    "        unique_summary += f\"religion_primary: {', '.join(sorted(unique_primary))}\\n\"\n",
    "        unique_summary += f\"religion_seriousness: {', '.join(sorted(unique_seriousness))}\\n\"\n",
    "    \n",
    "    # For the raw \"sign\" column, output the two new sign columns instead\n",
    "    elif col == 'sign':\n",
    "        unique_clean = df['sign_clean'].dropna().unique()\n",
    "        unique_importance = df['sign_importance'].dropna().unique()\n",
    "        unique_summary += f\"sign_clean: {', '.join(sorted(unique_clean))}\\n\"\n",
    "        unique_summary += f\"sign_importance: {', '.join(sorted(unique_importance))}\\n\"\n",
    "    \n",
    "    # Special cleaning for the \"pets\" column\n",
    "    elif col == 'pets':\n",
    "        unique_set = set()\n",
    "        for entry in df['pets'].dropna():\n",
    "            cleaned_pets = clean_pets(entry)\n",
    "            unique_set.update(cleaned_pets)\n",
    "        unique_str = \", \".join(sorted(unique_set))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "    \n",
    "    # For all other columns, simply list their unique values\n",
    "    else:\n",
    "        unique_values = df[col].dropna().unique()\n",
    "        unique_str = \", \".join(map(str, unique_values))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "\n",
    "# Print the final summary string\n",
    "print(unique_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 2. Combine Essay Columns\n",
    "# -----------------------------\n",
    "essay_cols = [f'essay{i}' for i in range(10) if f'essay{i}' in df.columns]\n",
    "df['essays'] = df[essay_cols].fillna('').agg(' '.join, axis=1)\n",
    "df.drop(columns=essay_cols, inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Clean Missing Values\n",
    "# -----------------------------\n",
    "categorical_cols = ['status', 'sex', 'orientation', 'body_type', 'diet',\n",
    "                    'drinks', 'drugs', 'education', 'ethnicity', 'job',\n",
    "                    'location', 'offspring', 'pets', 'religion', 'sign',\n",
    "                    'smokes', 'speaks']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"unknown\")\n",
    "\n",
    "numeric_cols = ['age', 'height', 'income']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 4. Outlier Detection and Removal\n",
    "# -----------------------------\n",
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "df = remove_outliers(df, numeric_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Create a Target Variable\n",
    "# -----------------------------\n",
    "df['target'] = (df['status'].str.lower() == 'single').astype(int)\n",
    "df.drop(columns=['status'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 6. Feature Engineering & Preprocessing Setup\n",
    "# -----------------------------\n",
    "numeric_features = ['age', 'height', 'income']\n",
    "categorical_features = [col for col in categorical_cols if col in df.columns and col != 'status']\n",
    "text_feature = 'essays'\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "        ('text', TfidfVectorizer(max_features=1000), text_feature)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "X = preprocessor.fit_transform(df)\n",
    "y = df['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 7. Split the Dataset\n",
    "# -----------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 8. Train XGBoost Model\n",
    "# -----------------------------\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8, \n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"  # Removed deprecated use_label_encoder\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "  Accuracy: 0.9369\n",
      "  ROC AUC:  0.7826\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 9. Evaluate the Model\n",
    "# -----------------------------\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "y_test_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"  Accuracy: {:.4f}\".format(test_accuracy))\n",
    "print(\"  ROC AUC:  {:.4f}\".format(test_roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Set Evaluation:\n",
      "  Accuracy: 0.9350\n",
      "  ROC AUC:  0.7829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 10. Evaluation on Validation Set\n",
    "# -----------------------------\n",
    "y_eval_pred = xgb_model.predict(X_eval)\n",
    "y_eval_prob = xgb_model.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "eval_accuracy = accuracy_score(y_eval, y_eval_pred)\n",
    "eval_roc_auc = roc_auc_score(y_eval, y_eval_prob)\n",
    "\n",
    "print(\"\\nEvaluation Set Evaluation:\")\n",
    "print(\"  Accuracy: {:.4f}\".format(eval_accuracy))\n",
    "print(\"  ROC AUC:  {:.4f}\".format(eval_roc_auc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
