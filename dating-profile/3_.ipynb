{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# -----------------------------\n",
    "# 1. Load the Dataset\n",
    "# -----------------------------\n",
    "file_path = '../data/okcupid_profiles_cleaned.csv'  # Updated file path\n",
    "new_df = pd.read_csv(file_path)\n",
    "# Set options to show all rows and columns without truncation\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)  # Prevent line wrapping for better visibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>religion_serious</th>\n",
       "      <th>sign</th>\n",
       "      <th>sign_note</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>essays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>['asian', 'white']</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['transportation']</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>california</td>\n",
       "      <td>south san francisco</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>['likes dogs', 'likes cats']</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>['english']</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>['white']</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>['hospitality', 'travel']</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>california</td>\n",
       "      <td>oakland</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>['likes dogs', 'likes cats']</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>['english', 'spanish', 'french']</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>[]</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>california</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['has cats']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>it doesn’t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>['english', 'french', 'c++']</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>['white']</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>['student']</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>california</td>\n",
       "      <td>berkeley</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>['likes cats']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>['english', 'german']</td>\n",
       "      <td>i work in a library and go to school. . . read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>['asian', 'black', 'other']</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['artistic', 'musical', 'writer']</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>california</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['likes dogs', 'likes cats']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>['english']</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet    drinks      drugs                          education                    ethnicity  height  income                                job       last_online     country                 city                               offspring                          pets     religion          religion_serious      sign          sign_note     smokes                            speaks                                             essays\n",
       "0   22     single   m    straight  a little extra  strictly anything  socially      never      working on college/university           ['asian', 'white']    75.0      -1                 ['transportation']  2012-06-28-20-30  california  south san francisco  doesn't have kids, but might want them  ['likes dogs', 'likes cats']  agnosticism     very serious about it    gemini                NaN  sometimes                       ['english']  about me:  i would love to think that i was so...\n",
       "1   35     single   m    straight         average       mostly other     often  sometimes              working on space camp                    ['white']    70.0   80000          ['hospitality', 'travel']  2012-06-29-21-41  california              oakland  doesn't have kids, but might want them  ['likes dogs', 'likes cats']  agnosticism  not too serious about it    cancer                NaN         no  ['english', 'spanish', 'french']  i am a chef: this is what that means. 1. i am ...\n",
       "2   38  available   m    straight            thin           anything  socially        NaN     graduated from masters program                           []    68.0      -1                                 []  2012-06-27-09-10  california        san francisco                                     NaN                  ['has cats']          NaN                       NaN    pisces  it doesn’t matter         no      ['english', 'french', 'c++']  i'm not ashamed of much, but writing public te...\n",
       "3   23     single   m    straight            thin         vegetarian  socially        NaN      working on college/university                    ['white']    71.0   20000                        ['student']  2012-06-28-14-22  california             berkeley                       doesn't want kids                ['likes cats']          NaN                       NaN    pisces                NaN         no             ['english', 'german']  i work in a library and go to school. . . read...\n",
       "4   29     single   m    straight        athletic                NaN  socially      never  graduated from college/university  ['asian', 'black', 'other']    66.0      -1  ['artistic', 'musical', 'writer']  2012-06-27-21-26  california        san francisco                                     NaN  ['likes dogs', 'likes cats']          NaN                       NaN  aquarius                NaN         no                       ['english']  hey how's it going? currently vague on the pro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: available, married, seeing someone, single, unknown\n",
      "sex: f, m\n",
      "orientation: bisexual, gay, straight\n",
      "body_type: a little extra, athletic, average, curvy, fit, full figured, jacked, overweight, rather not say, skinny, thin, used up\n",
      "diet: anything, halal, kosher, mostly anything, mostly halal, mostly kosher, mostly other, mostly vegan, mostly vegetarian, other, strictly anything, strictly halal, strictly kosher, strictly other, strictly vegan, strictly vegetarian, vegan, vegetarian\n",
      "drinks: desperately, not at all, often, rarely, socially, very often\n",
      "drugs: never, often, sometimes\n",
      "education: college/university, dropped out of college/university, dropped out of high school, dropped out of law school, dropped out of masters program, dropped out of med school, dropped out of ph.d program, dropped out of space camp, dropped out of two-year college, graduated from college/university, graduated from high school, graduated from law school, graduated from masters program, graduated from med school, graduated from ph.d program, graduated from space camp, graduated from two-year college, high school, law school, masters program, med school, ph.d program, space camp, two-year college, working on college/university, working on high school, working on law school, working on masters program, working on med school, working on ph.d program, working on space camp, working on two-year college\n",
      "ethnicity: ('asian', 'black', 'hispanic', 'indian', 'latin', 'middle eastern', 'native american', 'other', 'pacific islander', 'white')\n",
      "height: 1.0, 26.0, 3.0, 36.0, 37.0, 4.0, 42.0, 43.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 6.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 8.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 9.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0\n",
      "job: ('academia', 'administrative', 'artistic', 'banking', 'biz dev', 'clerical', 'computer', 'construction', 'craftsmanship', 'education', 'engineering', 'entertainment', 'executive', 'financial', 'government', 'hardware', 'health', 'hospitality', 'law', 'legal services', 'management', 'marketing', 'media', 'medicine', 'military', 'musical', 'other', 'political', 'rather not say', 'real estate', 'retired', 'sales', 'science', 'software', 'student', 'tech', 'transportation', 'travel', 'unemployed', 'writer')\n",
      "country: arizona, california, canada, colorado, connecticut, district of columbia, florida, georgia, germany, hawaii, idaho, illinois, ireland, louisiana, massachusetts, mexico, michigan, minnesota, mississippi, missouri, montana, netherlands, nevada, new jersey, new york, north carolina, ohio, oregon, pennsylvania, rhode island, spain, switzerland, tennessee, texas, united kingdom, utah, vietnam, virginia, washington, west virginia, wisconsin\n",
      "city: alameda, albany, amsterdam, arcadia, asheville, ashland, astoria, atherton, atlanta, austin, bayshore, bellingham, bellwood, belmont, belvedere tiburon, benicia, berkeley, billings, boise, bolinas, bonaduz, boston, boulder, brea, brisbane, brooklyn, burlingame, cambridge, campbell, canyon, canyon country, castro valley, chicago, chico, cincinnati, colma, columbus, concord, cork, corte madera, costa mesa, crockett, crowley, daly city, denver, east palo alto, edinburgh, el cerrito, el granada, el sobrante, emeryville, fairfax, fayetteville, forest knolls, fort lauderdale, foster city, freedom, fremont, glencove, grand rapids, granite bay, green brae, guadalajara, hacienda heights, half moon bay, hayward, hercules, hilarita, hillsborough, honolulu, irvine, isla vista, islip terrace, jackson, kansas city, kassel, kensington, kentfield, kula, lafayette, lagunitas, lake orion, larkspur, las vegas, leander, livingston, london, long beach, longwood, los angeles, los gatos, madrid, magalia, marin city, martinez, menlo park, miami, mill valley, millbrae, milpitas, milwaukee, minneapolis, modesto, montara, moraga, moss beach, mountain view, muir beach, murfreesboro, napa, nevada city, new orleans, new york, nha trang, nicasio, north hollywood, novato, oakland, oakley, oceanview, olema, orange, orinda, ozone park, pacheco, pacifica, palo alto, pasadena, peoria, petaluma, philadelphia, phoenix, piedmont, pinole, pleasant hill, point richmond, port costa, portland, providence, redwood city, redwood shores, richmond, riverside, rochester, rodeo, rohnert park, ross, sacramento, salt lake city, san anselmo, san antonio, san bruno, san carlos, san diego, san francisco, san geronimo, san jose, san leandro, san lorenzo, san luis obispo, san mateo, san pablo, san quentin, san rafael, santa ana, santa clara, santa cruz, santa monica, santa rosa, sausalito, seaside, seattle, south lake tahoe, south orange, south san francisco, south wellfleet, stanford, stinson beach, stockton, stratford, studio city, sunnyvale, taunton, tiburon, tucson, union city, utica, vacaville, vallejo, vancouver, british columbia, walnut creek, washington, waterford, west oakland, westlake, woodacre, woodbridge, woodside\n",
      "offspring: doesn't have kids, doesn't have kids, and doesn't want any, doesn't have kids, but might want them, doesn't have kids, but wants them, doesn't want kids, has a kid, has a kid, and might want more, has a kid, and wants more, has a kid, but doesn't want more, has kids, has kids, and might want more, has kids, and wants more, has kids, but doesn't want more, might want kids, wants kids\n",
      "pets: ('dislikes cats', 'dislikes dogs', 'has cats', 'has dogs', 'likes cats', 'likes dogs')\n",
      "religion: agnosticism, atheism, buddhism, catholicism, christianity, hinduism, islam, judaism, other\n",
      "religion_serious: laughing about it, not too serious about it, somewhat serious about it, very serious about it\n",
      "sign: aquarius, aries, cancer, capricorn, gemini, leo, libra, pisces, sagittarius, scorpio, taurus, virgo\n",
      "sign_note: it doesn’t matter, it matters a lot\n",
      "smokes: no, sometimes, trying to quit, when drinking, yes\n",
      "speaks: ('afrikaans', 'albanian', 'ancient greek', 'arabic', 'armenian', 'basque', 'belarusan', 'bengali', 'breton', 'bulgarian', 'c++', 'catalan', 'cebuano', 'chechen', 'chinese', 'croatian', 'czech', 'danish', 'dutch', 'english', 'esperanto', 'estonian', 'farsi', 'finnish', 'french', 'frisian', 'georgian', 'german', 'greek', 'gujarati', 'hawaiian', 'hebrew', 'hindi', 'hungarian', 'icelandic', 'ilongo', 'indonesian', 'irish', 'italian', 'japanese', 'khmer', 'korean', 'latin', 'latvian', 'lisp', 'lithuanian', 'malay', 'maori', 'mongolian', 'norwegian', 'occitan', 'other', 'persian', 'polish', 'portuguese', 'romanian', 'rotuman', 'russian', 'sanskrit', 'sardinian', 'serbian', 'sign language', 'slovak', 'slovenian', 'spanish', 'swahili', 'swedish', 'tagalog', 'tamil', 'thai', 'tibetan', 'turkish', 'ukrainian', 'urdu', 'vietnamese', 'welsh', 'yiddish')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Assume new_df is your cleaned DataFrame, for example:\n",
    "# new_df = pd.read_csv(\"okcupid_profiles_cleaned.csv\")\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Define columns to skip because they have too many unique values.\n",
    "skip_cols = ['age', 'income', 'last_online', 'essays']  # Removed 'country' and 'city'\n",
    "\n",
    "unique_summary = \"\"\n",
    "\n",
    "# Loop over every column in the cleaned DataFrame.\n",
    "for col in new_df.columns:\n",
    "    # Skip columns that we don't want to process.\n",
    "    if col in skip_cols:\n",
    "        continue\n",
    "\n",
    "    # Check if the column likely contains list data.\n",
    "    # We'll look at the first non-null value to decide.\n",
    "    sample_series = new_df[col].dropna()\n",
    "    if not sample_series.empty:\n",
    "        sample = sample_series.iloc[0]\n",
    "    else:\n",
    "        sample = None\n",
    "\n",
    "    # Function to try to convert a string representation to an actual list.\n",
    "    def ensure_list(entry):\n",
    "        if isinstance(entry, list):\n",
    "            return entry\n",
    "        elif isinstance(entry, str) and entry.strip().startswith('[') and entry.strip().endswith(']'):\n",
    "            try:\n",
    "                # Convert the string to an actual list.\n",
    "                converted = ast.literal_eval(entry)\n",
    "                if isinstance(converted, list):\n",
    "                    return converted\n",
    "                else:\n",
    "                    return [entry]\n",
    "            except Exception:\n",
    "                return [entry]\n",
    "        else:\n",
    "            return [entry]\n",
    "\n",
    "    # If the sample is a list or a string that looks like a list, then flatten the entire column.\n",
    "    if sample is not None and (isinstance(sample, list) or \n",
    "                               (isinstance(sample, str) and sample.strip().startswith('[') and sample.strip().endswith(']'))):\n",
    "        all_items = []\n",
    "        for entry in new_df[col].dropna():\n",
    "            # Ensure we have a list in any case.\n",
    "            items = ensure_list(entry)\n",
    "            all_items.extend(items)\n",
    "        unique_items = tuple(sorted(set(all_items)))\n",
    "        unique_summary += f\"{col}: {unique_items}\\n\"\n",
    "    else:\n",
    "        # For non-list columns, just take the unique values.\n",
    "        unique_values = new_df[col].dropna().unique()\n",
    "        # Sort and join as a string.\n",
    "        unique_str = \", \".join(sorted(map(str, unique_values)))\n",
    "        unique_summary += f\"{col}: {unique_str}\\n\"\n",
    "\n",
    "# Print the final unique summary string.\n",
    "print(unique_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
